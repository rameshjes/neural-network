{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class SOM:\n",
    "    def __init__(self,input_,num_of_nodes,eta,initial_wts,threshold):\n",
    "        self.input_ = input_\n",
    "        self.num_of_nodes = num_of_nodes\n",
    "        self.eta = eta\n",
    "        self.current_wts = initial_wts\n",
    "        self.t2 = 1000\n",
    "        self.threshold = threshold\n",
    "    \n",
    "    def euclidean_distance_1d(self,x,y):\n",
    "        return abs(x - y)\n",
    "    \n",
    "    def get_winning_neuron(self,x,W):\n",
    "        winner = min([(self.euclidean_distance_1d(x,w), index) for index,w in enumerate(W)])[1]\n",
    "        return winner\n",
    "    \n",
    "    def d_ij(self,winner):\n",
    "        distance = [self.euclidean_distance_1d(self.current_wts[winner],\\\n",
    "                                               self.current_wts[i])\\\n",
    "                    for i in range(len(self.current_wts))]\n",
    "        return distance\n",
    "    \n",
    "    def gaussian(self,sigma,distance):\n",
    "        h = [np.exp(-(d**2)/(2*sigma**2)) for d in distance]\n",
    "        return h\n",
    "    \n",
    "    def compute_width(self,initial_sigma,n,t1):\n",
    "        return initial_sigma*np.exp(-n/t1)\n",
    "    \n",
    "    def weight_adaptation(self,current_wt,eta,h,x):\n",
    "        new_wts = [(w + (eta*h*(x-w))) for w in current_wt]\n",
    "        return new_wts\n",
    "    \n",
    "    def exponential_decay_update(self,initial_eta,n,t2):\n",
    "        return initial_eta*np.exp(-n/t2)\n",
    "    \n",
    "    def compute_t1(self,t2):\n",
    "        sigma=2\n",
    "        return t2/np.log(sigma)\n",
    "    \n",
    "    def stopping_criteria(self,w_old,w_new):\n",
    "        result = 0\n",
    "        for i,w in enumerate(w_old):\n",
    "            result += abs(w - w_new[i])\n",
    "        \n",
    "        return True if (result < self.threshold) else False\n",
    "    \n",
    "    def train(self):\n",
    "        sigma = 2\n",
    "        t1 = self.compute_t1(self.t2)\n",
    "        n = 1\n",
    "        for x in self.input_:\n",
    "            while(True):\n",
    "                winning_neuron_idx = self.get_winning_neuron(x,self.current_wts)\n",
    "                lateral_dist = self.d_ij(winning_neuron_idx)\n",
    "                h = self.gaussian(sigma,lateral_dist)\n",
    "                updates_wts = self.weight_adaptation(self.current_wts,self.eta,h[winning_neuron_idx],x)\n",
    "\n",
    "                if not self.stopping_criteria(self.current_wts,updates_wts):\n",
    "                    self.current_wts =  np.array(updates_wts)\n",
    "                    self.eta = self.exponential_decay_update(self.eta,n,self.t2)\n",
    "                    n += 1 \n",
    "                else:\n",
    "                    break\n",
    "        print \"Final adjusted weights :\",self.current_wts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final adjusted weights : [ 0.14334454  0.4034118 ]\n"
     ]
    }
   ],
   "source": [
    "initial_wts = np.array([[0.15,0.45],\n",
    "                        [0.3,0.9]])\n",
    "inputs = [0.1,0.2,0.4,0.5]\n",
    "som = SOM(inputs,2,0.1,initial_wts[0],0.01)\n",
    "som.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
